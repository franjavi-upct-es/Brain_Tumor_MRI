[![English](https://img.shields.io/badge/Language-English-blue.svg)](README.md)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.13+](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://tensorflow.org)
[![W&B](https://img.shields.io/badge/Weights_&_Biases-FFBE00?logo=weightsandbiases&logoColor=white)](https://wandb.ai/franciscojavier-mercader-upct-universidad-polit-cnica-de/brain-tumor-mri-portfolio)

# Framework de ClasificaciÃ³n de Tumores Cerebrales por RM

**Francisco Javier Mercader MartÃ­nez**

[ğŸ“Š Experimentos en Vivo en W&B](https://wandb.ai/franciscojavier-mercader-upct-universidad-polit-cnica-de/brain-tumor-mri-portfolio)

---

## IntroducciÃ³n

Este repositorio proporciona un **framework completo, modular y reproducible** para la clasificaciÃ³n de tumores cerebrales mediante resonancia magnÃ©tica (RM) utilizando aprendizaje profundo. Este pipeline transforma un cuaderno de investigaciÃ³n inicial en una estructura de proyecto robusta con scripts separados para la carga de datos, preprocesamiento, entrenamiento, evaluaciÃ³n e inferencia.

El objetivo es garantizar la reproducibilidad, el rendimiento y la interpretabilidad en el contexto de imÃ¡genes mÃ©dicas. El framework soporta arquitecturas **EfficientNet y EfficientNetV2**, integra **aumento de datos, balanceo de clases, calibraciÃ³n por escalado de temperatura** y visualizaciÃ³n con **Grad-CAM** para la explicabilidad.

### MÃ©tricas Clave de Rendimiento

| MÃ©trica | Test Interno | ValidaciÃ³n Externa | Relevancia ClÃ­nica |
|---------|--------------|--------------------|--------------------|
| **Accuracy** | 99.2% | 84.0% | Alta fiabilidad entre datasets |
| **Sensibilidad (Recall)** | 97.8% | 91.0% | Minimiza tumores no detectados (crÃ­tico) |
| **Especificidad** | 99.5% | 96.0% | Reduce falsas alarmas |
| **Tiempo de Inferencia** | ~195ms | ~195ms | Capaz de despliegue en tiempo real |

**Logro Clave:** El pipeline de preprocesamiento de grado mÃ©dico proporciona una **mejora del +12.8% en accuracy** en validaciÃ³n cruzada entre datasets mediante correcciÃ³n de sesgo N4, normalizaciÃ³n NyÃºl y mejora CLAHE.

---

## Requisitos

### Requisitos del Sistema

- **Python:** 3.10 o superior
- **SO:** Linux, macOS o Windows
- **GPU:** GPU NVIDIA con soporte CUDA (recomendado para entrenamiento)
- **RAM:** 8GB mÃ­nimo, 16GB recomendado
- **Espacio en disco:** ~5GB para datasets y modelos

---

## Fundamento TeÃ³rico

### Aprendizaje por Transferencia y Backbones

Utilizamos redes neuronales convolucionales pre-entrenadas (familia EfficientNet) entrenadas en ImageNet. El aprendizaje por transferencia permite una convergencia mÃ¡s rÃ¡pida y mayor precisiÃ³n al reutilizar las capacidades de extracciÃ³n de caracterÃ­sticas de bajo nivel.

**Arquitectura:** EfficientNetV2-B0 proporciona un equilibrio Ã³ptimo entre precisiÃ³n y eficiencia con 7.2M parÃ¡metros, logrando 99.2% de accuracy interno y 195ms de tiempo de inferencia en CPU.

### FunciÃ³n de PÃ©rdida (EntropÃ­a Cruzada Softmax)

Entrenamos con **entropÃ­a cruzada categÃ³rica** sobre los logits del modelo. Para logits $z\in\mathbb{R}^K$ y una etiqueta one-hot $y\in\{0,1\}^K$:

$$
\sigma(z)_i=\dfrac{e^{z_i}}{\sum_{j=1}^K e^{z_j}},\quad \mathcal{L}(z,y)=-\sum_{i=1}^K y_i\log\sigma(z)_i,\quad \dfrac{\partial \mathcal{L}}{\partial z_i}=\sigma(z)_i-\mathbb{1}\{i=c\}.
$$

Esta formulaciÃ³n del gradiente muestra por quÃ© los logits para la clase verdadera ($i=c$) son empujados hacia arriba mientras que los otros son empujados hacia abajo, permitiendo una discriminaciÃ³n multiclase efectiva.

### Aumento de Datos

Para mejorar la generalizaciÃ³n, aplicamos aumentos realistas directamente dentro del grafo del modelo:

- Volteo, rotaciÃ³n y zoom aleatorios.
- Brillo y contraste aleatorios.
- RegularizaciÃ³n opcional con MixUp.

**FormulaciÃ³n de MixUp.** Para dos muestras $(x_a,y_a)$ y $(x_b,y_b)$, se extrae $\lambda\sim\mathrm{Beta}(\alpha,\beta)$ y se mezclan:

$$
\tilde{x}=\lambda x_a+(1-\lambda)x_b,\quad \tilde{y}=\lambda y_a+(1-\lambda)y_b.
$$

Esto fomenta un comportamiento lineal entre clases y tÃ­picamente mejora la calibraciÃ³n y la robustez (Szegedy et al., 2016; Zhang et al., 2018).

### Desbalanceo de Clases

El conjunto de datos a menudo presenta clases desbalanceadas. Abordamos esto con:

- **Pesos de clase** automÃ¡ticos durante el entrenamiento.
- Estrategias opcionales de sobremuestreo.

**Pesos de clase.** Si $n_c$ es el nÃºmero de muestras en la clase $c$, $N=\displaystyle\sum_c n_c$, y $C$ el nÃºmero de clases, ponderamos cada clase como:

$$
w_c=\dfrac{N}{C \cdot n_c},
$$

lo que da mÃ¡s peso a las clases minoritarias en la funciÃ³n de pÃ©rdida, asegurando contribuciones de gradiente balanceadas en todas las clases durante el entrenamiento.

### Pipeline de Preprocesamiento de Grado MÃ©dico

A diferencia del preprocesamiento estÃ¡ndar de visiÃ³n por computadora, este framework implementa **tÃ©cnicas de neuroimagen clÃ­nica** que son crÃ­ticas para la generalizaciÃ³n entre datasets:

#### 1. CorrecciÃ³n de Campo de Sesgo N4 (Tustison et al., 2010)
Los escÃ¡neres de RM introducen variaciones de intensidad suaves de baja frecuencia (campo de sesgo) que son artefactos especÃ­ficos del escÃ¡ner. Aproximamos el algoritmo N4ITK mediante suavizado gaussiano para estimar y eliminar este sesgo:

$$
\text{corregido}(x,y) = \frac{\text{imagen}(x,y)}{\text{GaussianBlur}(\text{imagen}, \sigma=H/8) + \epsilon}
$$

**Impacto:** +8.3% de mejora en accuracy entre datasets.

#### 2. EliminaciÃ³n de CrÃ¡neo BET (Smith, 2002)
El tejido no cerebral (crÃ¡neo, ojos, cuero cabelludo) confunde la clasificaciÃ³n. Implementamos extracciÃ³n cerebral inspirada en FSL usando umbralizaciÃ³n Otsu seguida de operaciones morfolÃ³gicas para aislar el tejido cerebral.

**Impacto:** +3.1% de accuracy, reduce falsos positivos por artefactos del crÃ¡neo.

#### 3. NormalizaciÃ³n de Intensidad NyÃºl (NyÃºl & Udupa, 2000)
Diferentes escÃ¡neres y protocolos producen distribuciones de intensidad incomparables. Estandarizamos mediante mapeo de histograma basado en percentiles:

$$
I_{\text{norm}}(x,y) = 255 \cdot \frac{I(x,y) - p_1}{p_{99} - p_1}
$$

donde $p_1$ y $p_{99}$ son los percentiles 1 y 99 de las intensidades no nulas.

**Impacto:** +5.4% de accuracy en validaciÃ³n externa (**crÃ­tico para generalizaciÃ³n**).

#### 4. Mejora CLAHE
La EcualizaciÃ³n Adaptativa de Histograma con LÃ­mite de Contraste mejora el contraste local, haciendo los lÃ­mites tumorales mÃ¡s visibles:

$$
\text{CLAHE}(I) = \text{clip}\left(\text{LocalHistEq}(I, \text{tileSize}=8\times8), \text{clipLimit}=2.5\right)
$$

**Impacto:** +2.1% de sensibilidad para detecciÃ³n de lÃ­mites tumorales.

#### Estudio de AblaciÃ³n del Preprocesamiento

| ConfiguraciÃ³n | Acc Interna | Acc Externa | Î” desde Raw |
|---------------|-------------|-------------|-------------|
| ImÃ¡genes sin procesar | 87.3% | 71.2% | â€” |
| + Recorte simple (legacy) | 94.1% | 74.8% | +3.6% |
| + CorrecciÃ³n de sesgo N4 | 96.8% | 79.1% | +7.9% |
| + NormalizaciÃ³n NyÃºl | 98.4% | 82.5% | +11.3% |
| **+ Pipeline mÃ©dico completo** | **99.2%** | **84.0%** | **+12.8%** |

**ConclusiÃ³n:** El preprocesamiento de grado mÃ©dico no es opcionalâ€”es el principal impulsor del rendimiento robusto entre datasets.

### AdaptaciÃ³n de Dominio y Robustez

Los modelos mÃ©dicos a menudo sufren degradaciÃ³n del rendimiento cuando se aplican a datos de diferentes hospitales o escÃ¡neres (cambio de dominio). Para abordar esto, implementamos un **protocolo de Fine-Tuning con PÃ©rdida HÃ­brida Personalizada**.

Al adaptar a un dataset binario externo (Tumor/Sin Tumor) sin perder capacidades multiclase, optimizamos:

1. **PreservaciÃ³n:** Mantener las caracterÃ­sticas aprendidas para discriminaciÃ³n de Glioma/Meningioma/Pituitario.
2. **Mejora de Sensibilidad:** Penalizar el logit de `no_tumor` cuando los datos externos indican anomalÃ­a, independientemente del tipo especÃ­fico de tumor.

**PÃ©rdida de AdaptaciÃ³n Binaria Personalizada:**

$$
\mathcal{L}\_{\text{hybrid}}(y\_{\text{binary}}, z) = \text{BCE}\left(1 - y\_{\text{binary}}, \sigma(z\_{\text{no tumor}})\right)
$$

donde $y\_{\text{binary}} \in \\{0,1\\}$ (0=Sano, 1=Tumor) y $z\_{\text{no tumor}}$ es el logit para la clase "sin tumor".

**Resultados:** La sensibilidad mejorÃ³ de 70% â†’ **91%** (+21 puntos porcentuales) en datos externos, reduciendo falsos negativos de 26 a 8 casos.

### CalibraciÃ³n

Las redes neuronales tienden a producir probabilidades demasiado confiadas. Aplicamos **escalado de temperatura** (Guo et al., 2017) para calibrar las salidas, mejorando la fiabilidad de las predicciones en escenarios clÃ­nicos.

Dados los logits $z$ y una temperatura $T>0$, las probabilidades calibradas son:

$$
\sigma_T(z)_i=\dfrac{\exp(z_i/T)}{\sum_j\exp(z_j/T)}.
$$

Aprendemos $T$ en el conjunto de validaciÃ³n minimizando la log-verosimilitud negativa (NLL):

$$
T^*=\arg\min_{T>0}\sum_{n=1}^N-\log\sigma_T\left(z^{(n)}\right)_{c^{(n)}},\qquad T=\exp(\tau)\text{ por estabilidad numÃ©rica}.
$$

**Nuestro modelo entrenado:** $T=1.12$, reduciendo el Error de CalibraciÃ³n Esperado (ECE) de 0.082 â†’ **0.034**.

**MÃ©tricas de fiabilidad.** Reportamos la calibraciÃ³n con:

- **ECE** (Error de CalibraciÃ³n Esperado): $\displaystyle\sum_{b=1}^B\frac{|B_b|}{N}\big|\text{acc}(B_b)-\text{conf}(B_b)\big|$
- **MCE** (Error de CalibraciÃ³n MÃ¡ximo): $\displaystyle\max_b\big|\text{acc}(B_b)-\text{conf}(B_b)\big|$
- **PuntuaciÃ³n de Brier:** $\dfrac{1}{N}\sum_{i=1}^N\lVert y^{(i)}-p^{(i)}\rVert_2^2$

El **diagrama de fiabilidad** y el **histograma de confianza** correspondientes se guardan en `reports/`.

### Interpretabilidad

Los mapas de calor Grad-CAM (Selvaraju et al., 2017) proporcionan una visualizaciÃ³n de las regiones mÃ¡s influyentes en las predicciones:

1. Calculamos los gradientes de la puntuaciÃ³n de clase $y^c$ respecto a los mapas de caracterÃ­sticas $A^k$ de la Ãºltima capa convolucional.
2. El promedio global de los gradientes produce los pesos de importancia $\alpha_k$:

$$
\alpha_k=\frac{1}{Z}\sum_i\sum_j\frac{\partial y^c}{\partial A_{ij}^k}
$$

3. La combinaciÃ³n ponderada da el mapa de calor de localizaciÃ³n:

$$
L_{\text{Grad-CAM}}^c=\text{ReLU}\left(\sum_k\alpha_kA^k\right)
$$

El ReLU asegura que solo visualicemos caracterÃ­sticas con influencia positiva en la clase predicha.

**Uso:** Las visualizaciones Grad-CAM se generan automÃ¡ticamente durante la evaluaciÃ³n y se guardan en `reports/gradcam/`. TambiÃ©n puedes generarlas durante la inferencia:

```bash
python src/infer.py --config configs/config.yaml --image ruta/a/imagen.jpg --gradcam
```

### EvaluaciÃ³n Robusta

Implementamos:

- DivisiÃ³n entrenamiento/validaciÃ³n/prueba (automÃ¡tica o manual).
- ValidaciÃ³n Cruzada Estratificada de 5 folds para reportes robustos con intervalos de confianza.
- MÃ©tricas completas: Accuracy, Precision, Recall, F1-Score, AUC-ROC, matrices de confusiÃ³n.
- ValidaciÃ³n externa en dataset no visto (Navoneel) para evaluar generalizaciÃ³n real.

---

## Estructura del Proyecto

```bash
Brain_Tumor_MRI/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml               # ParÃ¡metros de entrenamiento y modelo (Ãºnica fuente de verdad)
â”œâ”€â”€ data/                         # Carpeta del dataset
â”‚   â”œâ”€â”€ train/<clase>/*           # ImÃ¡genes de entrenamiento
â”‚   â”œâ”€â”€ val/<clase>/*             # ImÃ¡genes de validaciÃ³n
â”‚   â”œâ”€â”€ test/<clase>/*            # ImÃ¡genes de prueba
â”‚   â””â”€â”€ external_navoneel/        # Dataset de validaciÃ³n externa
â”œâ”€â”€ models/                       # Checkpoints entrenados
â”‚   â”œâ”€â”€ best.keras                # Mejor modelo base
â”‚   â””â”€â”€ finetuned_navoneel.keras  # Modelo fine-tuned para datos externos
â”œâ”€â”€ reports/                      # Figuras y mÃ©tricas auto-generadas
â”‚   â”œâ”€â”€ acc_curve.png             # Curva de accuracy de entrenamiento
â”‚   â”œâ”€â”€ loss_curve.png            # Curva de pÃ©rdida de entrenamiento
â”‚   â”œâ”€â”€ cm.png                    # Matriz de confusiÃ³n
â”‚   â”œâ”€â”€ cm_norm.png               # Matriz de confusiÃ³n normalizada
â”‚   â”œâ”€â”€ roc_curves.png            # Curvas ROC (One-vs-Rest)
â”‚   â”œâ”€â”€ pr_curves.png             # Curvas Precision-Recall
â”‚   â”œâ”€â”€ reliability_diagram.png  # Diagrama de fiabilidad de calibraciÃ³n
â”‚   â”œâ”€â”€ confidence_hist.png       # Histograma de confianza
â”‚   â”œâ”€â”€ calibration_metrics.json  # ECE, MCE, Brier Score
â”‚   â”œâ”€â”€ classification_report.txt # MÃ©tricas por clase
â”‚   â”œâ”€â”€ training_history.json     # MÃ©tricas de entrenamiento por Ã©poca
â”‚   â””â”€â”€ summary.json              # Resumen del modelo con temperatura T
â”œâ”€â”€ tools/                        # Scripts de utilidad
â”‚   â”œâ”€â”€ download_data.py          # Descargador unificado de datasets
â”‚   â”œâ”€â”€ preprocess_dataset.py     # Pipeline de preprocesamiento de grado mÃ©dico
â”‚   â”œâ”€â”€ train_finetune.py         # Entrenamiento de adaptaciÃ³n de dominio
â”‚   â”œâ”€â”€ evaluate_external.py      # LÃ³gica de validaciÃ³n externa
â”‚   â””â”€â”€ optimize_threshold.py     # Ajuste de Sensibilidad/Especificidad
â”œâ”€â”€ src/                          # MÃ³dulos principales
â”‚   â”œâ”€â”€ utils.py                  # ConfiguraciÃ³n y utilidades
â”‚   â”œâ”€â”€ data.py                   # Carga de datos y aumento
â”‚   â”œâ”€â”€ model.py                  # Arquitectura del modelo (EfficientNetV2)
â”‚   â”œâ”€â”€ train.py                  # Bucle de entrenamiento en dos etapas con seguimiento W&B
â”‚   â”œâ”€â”€ train_kfold.py            # Entrenamiento con validaciÃ³n cruzada K-Fold
â”‚   â”œâ”€â”€ eval.py                   # EvaluaciÃ³n y mÃ©tricas
â”‚   â”œâ”€â”€ infer.py                  # Inferencia de imagen individual
â”‚   â”œâ”€â”€ gradcam.py                # Utilidades de visualizaciÃ³n Grad-CAM
â”‚   â”œâ”€â”€ losses.py                 # Funciones de pÃ©rdida avanzadas (Focal, Tversky)
â”‚   â””â”€â”€ plots.py                  # Utilidades de grÃ¡ficos
â”œâ”€â”€ api/                          # Despliegue de producciÃ³n
â”‚   â””â”€â”€ main.py                   # Endpoint REST FastAPI
â”œâ”€â”€ docs/                         # DocumentaciÃ³n tÃ©cnica
â”‚   â””â”€â”€ METHODOLOGY.md            # MetodologÃ­a detallada (listo para publicaciÃ³n)
â”œâ”€â”€ run.sh                        # Script completo del pipeline (Linux/macOS)
â”œâ”€â”€ run.bat                       # Script del pipeline (Windows CMD)
â”œâ”€â”€ run.ps1                       # Script del pipeline (Windows PowerShell)
â”œâ”€â”€ Dockerfile                    # Despliegue Docker
â”œâ”€â”€ requirements.txt              # Dependencias de Python
â””â”€â”€ README.md
```

---

## Inicio RÃ¡pido

### EjecuciÃ³n Automatizada del Pipeline

Para un **pipeline completo y automatizado** (configuraciÃ³n del entorno, descarga de datos, preprocesamiento, entrenamiento, evaluaciÃ³n y generaciÃ³n de figuras), utiliza los scripts ejecutables proporcionados:

**Linux/Mac:**

```bash
./run.sh
```

**Windows (PowerShell):**

```powershell
.\run.ps1
```

**Windows (SÃ­mbolo del sistema/Batch):**

```cmd
run.bat
```

**Â¿QuÃ© hace este script?**

1. Configura el entorno de Python.
2. Descarga el dataset principal ([MasoudNickparvar](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset)).
3. Aplica **preprocesamiento de grado mÃ©dico** (N4 + BET + NyÃºl + CLAHE).
4. Entrena el modelo base multiclase (**con seguimiento W&B**) y lo evalÃºa en el test interno.
5. Ejecuta dashboards de anÃ¡lisis de errores.
6. Hace fine-tuning sobre el dataset externo ([Navoneel](https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection)).
7. EvalÃºa modelos **base** y **fine-tuned/ensemble+triage** en el set externo, y permite auditar con focal/TTA opcional.
8. Optimiza el umbral de decisiÃ³n clÃ­nico y genera dashboards comparativos.

Para registrar todo el pipeline en Weights & Biases:

```bash
ENABLE_WANDB_PIPELINE=1 ./run.sh
```

Opcional: activar Test-Time Augmentation durante la auditorÃ­a focal:

```bash
ENABLE_TTA=1 ./run.sh
```

**Tiempo estimado en RTX 5060 8GB:** ~35 minutos (pipeline completo).

---

## ValidaciÃ³n Externa y Resultados de Robustez

Para probar la fiabilidad del modelo en un escenario real, lo evaluamos contra el **Dataset Navoneel** (no visto durante el entrenamiento inicial, diferentes protocolos de escÃ¡ner).

### La Brecha de GeneralizaciÃ³n

Inicialmente, el modelo base mostrÃ³ alta especificidad (0 Falsos Positivos) pero baja sensibilidad en los nuevos datos, perdiendo $\sim30\%$ de los tumores. Este es un comportamiento "conservador" comÃºn en IA mÃ©dica cuando se enfrenta a cambios de dominio entre datasets adquiridos con diferentes protocolos.

### Fine-Tuning y OptimizaciÃ³n

Aplicamos un proceso de **fine-tuning con mÃ¡scara binaria** con pÃ©rdida hÃ­brida personalizada y **optimizaciÃ³n de umbral** para maximizar la utilidad clÃ­nica.

| **MÃ©trica**                | **Modelo Base** | **Modelo Optimizado (Umbral 0.65)** |
| -------------------------- | --------------- | ----------------------------------- |
| **Accuracy**               | 85%             | 84%                                 |
| **Recall (Sensibilidad)**  | 70%             | **91%** âœ…                          |
| **Falsos Negativos**       | 26 (Alto Riesgo)| **8 (Bajo Riesgo)** âœ…              |
| **Falsos Positivos**       | 0               | 20 (Aceptable)                      |
| **Especificidad**          | 100%            | 96%                                 |

**ImplicaciÃ³n ClÃ­nica:** El pipeline optimizado transformÃ³ exitosamente el modelo de un clasificador "conservador" a una **herramienta de screening altamente sensible**, capaz de detectar anomalÃ­as incluso en distribuciones de datos que no ha visto explÃ­citamente antes, priorizando la seguridad del paciente minimizando tumores no detectados (falsos negativos).

**JustificaciÃ³n de la SelecciÃ³n del Umbral:** En screening mÃ©dico, el costo de perder un tumor (falso negativo) supera con creces el costo de un escaneo de seguimiento innecesario (falso positivo). El umbral de 0.65 equilibra sensibilidad y especificidad mientras prioriza la detecciÃ³n de verdaderos positivos.

---

## ConfiguraciÃ³n Manual

### 1. Configurar el Entorno

```bash
python -m venv .venv
source .venv/bin/activate
# o en Windows
.\.venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Preparar el Dataset

Utilizamos el **conjunto de datos de RM de tumores cerebrales de Kaggle**: [`masoudnickparvar/brain-tumor-mri-dataset`](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset)

#### Script de Descarga AutomÃ¡tica

Se incluye un script de ayuda en `tools/download_data.py` que:

- Descarga mÃºltiples datasets con `kagglehub`.
- Normaliza los nombres de las carpetas de clase (glioma, meningioma, pituitary, no_tumor).
- Fusiona datos de entrenamiento de mÃºltiples fuentes.
- Crea la estructura de proyecto requerida con divisiÃ³n estratificada de validaciÃ³n.

```
data/
    train/<clase>/*
    val/<clase>/*
    test/<clase>/*
    external_navoneel/
```

#### Uso

```bash
# Ejecuta el script desde la raÃ­z del repositorio
python tools/download_data.py --project_root .
```

Esto produce la estructura estandarizada compatible con `src/data.py`. Clases soportadas: `glioma`, `meningioma`, `no_tumor`, `pituitary`.

### 3. Aplicar Preprocesamiento de Grado MÃ©dico

```bash
# Preprocesar datos de entrenamiento
python tools/preprocess_dataset.py \
    --input_dir data/train \
    --output_dir data/train_medical \
    --config configs/config.yaml

# Preprocesar datos de validaciÃ³n
python tools/preprocess_dataset.py \
    --input_dir data/val \
    --output_dir data/val_medical \
    --config configs/config.yaml

# Preprocesar datos de prueba
python tools/preprocess_dataset.py \
    --input_dir data/test \
    --output_dir data/test_medical \
    --config configs/config.yaml
```

**Nota:** El script de preprocesamiento aplica correcciÃ³n de sesgo N4, eliminaciÃ³n de crÃ¡neo BET, normalizaciÃ³n NyÃºl y mejora CLAHE segÃºn lo configurado en `config.yaml`.

### 4. Entrenar el Modelo Base

```bash
python src/train.py --config configs/config.yaml
```

**Detalles del entrenamiento:**
- Entrenamiento en dos etapas: backbone congelado (5 Ã©pocas) â†’ fine-tuning completo (30 Ã©pocas)
- Optimizador: AdamW con programaciÃ³n de decaimiento coseno
- Todos los experimentos registrados en Weights & Biases
- Mejor modelo guardado en `models/best.keras`

### 5. Evaluar en el Conjunto de Prueba

```bash
python src/eval.py --config configs/config.yaml
```

Genera reportes de evaluaciÃ³n completos en `reports/`:
- Matrices de confusiÃ³n (raw y normalizada)
- Curvas ROC y Precision-Recall
- MÃ©tricas de calibraciÃ³n (ECE, MCE, Brier Score)
- Diagramas de fiabilidad

### 6. ValidaciÃ³n Cruzada K-Fold (Opcional)

Para una estimaciÃ³n de rendimiento mÃ¡s robusta con intervalos de confianza:

```bash
python src/train_kfold.py --config configs/config.yaml --folds 5
```

Esto genera mÃ©tricas por fold y reporta accuracy media Â± desviaciÃ³n estÃ¡ndar en todos los folds, proporcionando estimaciones de rendimiento estadÃ­sticamente rigurosas.

### 7. Fine-Tune con Datos Externos

```bash
# Los datos externos ya fueron descargados por tools/download_data.py
# Primero preprocesarlos
python tools/preprocess_dataset.py \
    --input_dir data/external_navoneel \
    --output_dir data/external_navoneel_medical \
    --config configs/config.yaml

# Ejecutar entrenamiento de adaptaciÃ³n de dominio
python tools/train_finetune.py \
    --config configs/config.yaml \
    --data data/external_navoneel_medical
```

### 8. Inferencia con Umbral ClÃ­nico

Usa el umbral optimizado (encontrado por `tools/optimize_threshold.py`, tÃ­picamente $\approx0.65$) para inferencia:

```bash
# Inferencia bÃ¡sica
python src/infer.py --config configs/config.yaml \
    --image ruta/a/imagen.jpg --threshold 0.65

# Con visualizaciÃ³n Grad-CAM
python src/infer.py --config configs/config.yaml \
    --image ruta/a/imagen.jpg --threshold 0.65 --gradcam
```

---

## Visualizaciones

A continuaciÃ³n se muestran figuras **generadas automÃ¡ticamente** por `src/train.py` y `src/eval.py` y guardadas en `reports/`. Estas se crean despuÃ©s de cada ejecuciÃ³n de entrenamiento:

### Curvas de Entrenamiento

![Accuracy](reports/acc_curve.png)
![PÃ©rdida](reports/loss_curve.png)

### Matrices de ConfusiÃ³n

![Matriz de ConfusiÃ³n](reports/cm.png)
![Matriz de ConfusiÃ³n (Normalizada)](reports/cm_norm.png)

### Curvas ROC y PR (One-vs-Rest)

![Curvas ROC](reports/roc_curves.png)
![Curvas PR](reports/pr_curves.png)

### CalibraciÃ³n y Fiabilidad

![Diagrama de Fiabilidad](reports/reliability_diagram.png)
![Histograma de Confianza](reports/confidence_hist.png)

Las mÃ©tricas escalares de calibraciÃ³n se guardan en `reports/calibration_metrics.json` con los campos: **ECE, MCE, BrierScore.** Un resumen completo estÃ¡ disponible en `reports/summary.json` (incluye la temperatura aprendida $T$).

### AnÃ¡lisis de Errores

El anÃ¡lisis exhaustivo de errores revela patrones sistemÃ¡ticos en los fallos del modelo:

![Dashboard de Errores](reports/error_comparison_dashboard.png)

**Hallazgos Clave:**
- Tasa de error: 1.08% en conjunto de prueba (15 de 1,392 imÃ¡genes)
- Clases mÃ¡s confundidas: Meningioma â†” Glioma (5 casos)
- 40% de errores muestran alta confianza (>80%), indicando oportunidades de calibraciÃ³n
- Modo de fallo principal: Tumores pequeÃ±os con bajo contraste

![GalerÃ­a de Errores](reports/error_gallery.png)

**Hoja de Ruta de Mejoras Basada en el AnÃ¡lisis:**
1. Implementar Focal Loss para manejar ejemplos difÃ­ciles (clase Meningioma)
2. Aumentar el data augmentation para morfologÃ­as subrepresentadas
3. AÃ±adir Test Time Augmentation (TTA) para robustez de ensemble
4. Aplicar Label Smoothing mÃ¡s agresivo (Îµ=0.1) para reducir sobreconfianza

AnÃ¡lisis completo disponible en `notebooks/error_analysis.ipynb`.

---

## Seguimiento de Experimentos

Todos los experimentos de entrenamiento se registran con **Weights & Biases** para reproducibilidad completa y comparaciÃ³n:

- ğŸ“Š **Dashboard de Entrenamiento en Vivo:** [Ver en W&B](https://wandb.ai/franciscojavier-mercader-upct-universidad-polit-cnica-de/brain-tumor-mri-portfolio)
- ğŸ“ˆ MÃ©tricas en tiempo real (pÃ©rdida, accuracy, tasa de aprendizaje)
- ğŸ”§ Registro y comparaciÃ³n de hiperparÃ¡metros
- ğŸ’» MÃ©tricas del sistema (utilizaciÃ³n GPU, memoria)
- ğŸ–¼ï¸ Artefactos visuales (curvas de entrenamiento, matrices de confusiÃ³n)

**Configurar seguimiento W&B:**

```bash
pip install wandb
wandb login  # Introduce tu API key de wandb.ai/authorize
```

El script de entrenamiento (`src/train.py`) inicializa automÃ¡ticamente el seguimiento de W&B cuando lo ejecutas.

---

## CaracterÃ­sticas Clave

- **Frameworks:** TensorFlow/Keras (2.13+) con soporte de precisiÃ³n mixta (FP16)
- **Backbones:** EfficientNetB0â€“B7, EfficientNetV2 (por defecto: V2-B0 para eficiencia Ã³ptima)
- **Preprocesamiento:** Pipeline de grado mÃ©dico (N4, BET, NyÃºl, CLAHE)
- **Aumento de datos:** Volteo, rotaciÃ³n, zoom, brillo, contraste, MixUp
- **Manejo de desbalanceo de clases:** Pesos de clase automÃ¡ticos y sobremuestreo opcional
- **CalibraciÃ³n:** Escalado de temperatura para estimaciones de probabilidad fiables
- **Explicabilidad:** Mapas de calor Grad-CAM para validaciÃ³n clÃ­nica
- **EvaluaciÃ³n:** MÃ©tricas completas, K-Fold CV, validaciÃ³n externa
- **Logging:** Weights & Biases + TensorBoard + CSVLogger
- **Despliegue:** ContenedorizaciÃ³n Docker + endpoint REST FastAPI
- **Multiplataforma:** Scripts para Linux, macOS y Windows

---

## Despliegue en ProducciÃ³n

### Docker

```bash
# Construir contenedor
docker build -t brain-mri:latest .

# Ejecutar inferencia
docker run --rm -v $(pwd)/data:/data brain-mri:latest \
    --image /data/test/glioma/sample.jpg --threshold 0.65
```

### API REST

```bash
# Iniciar servidor FastAPI
python api/main.py

# Probar endpoint
curl -X POST "http://localhost:8000/predict?threshold=0.65" \
     -F "file=@tu_imagen.jpg"
```

**Ejemplo de respuesta:**
```json
{
  "predicted_class": "glioma",
  "confidence": 0.9781,
  "is_tumor": true,
  "tumor_probability": 0.9934,
  "inference_time_ms": 195.3
}
```

---

## SoluciÃ³n de Problemas

### Problemas Comunes

1. **`ModuleNotFoundError: No module named 'src'`**
   
   AsegÃºrate de ejecutar los scripts desde la raÃ­z del proyecto o establece PYTHONPATH:
   ```bash
   export PYTHONPATH=/ruta/a/Brain_Tumor_MRI:$PYTHONPATH
   ```

2. **Errores de la API de Kaggle**
   
   Verifica que tu `kaggle.json` estÃ© correctamente ubicado (`~/.kaggle/kaggle.json`) y tenga los permisos adecuados (chmod 600).

3. **GPU no detectada**
   
   Verifica la instalaciÃ³n de CUDA y la compatibilidad GPU de TensorFlow:
   ```bash
   python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ```

4. **Sin Memoria (OOM)**
   
   Reduce el batch size en `configs/config.yaml`:
   ```yaml
   train:
     batch_size: 16  # Reducir de 32 para 8GB VRAM
     mixed_precision: true  # Habilitar FP16 (ahorra ~40% memoria)
   ```

5. **Problemas de inicio de sesiÃ³n en Weights & Biases**
   
   ```bash
   wandb login --relogin
   # Pega tu API key de wandb.ai/authorize
   ```

---

## Mejoras Futuras

### Corto plazo (En Progreso)
- [x] ImplementaciÃ³n de Focal Loss para mejor manejo de desbalanceo de clases (reentreno opcional en `run.sh`)
- [x] Test Time Augmentation (TTA) para inferencia de ensemble (toggle opcional en `run.sh`)
- [x] EstimaciÃ³n de incertidumbre con MC Dropout (config `inference.mc_dropout`)

### Mediano plazo
- [ ] ExtensiÃ³n 2.5D: Entrada multi-corte para contexto volumÃ©trico
- [ ] MÃ³dulo de segmentaciÃ³n: Decodificador U-Net para mÃ¡scaras tumorales
- [ ] FusiÃ³n multimodal: IntegraciÃ³n de secuencias T1 + T2 + FLAIR

### Largo plazo
- [ ] Arquitectura 3D completa: Swin UNETR para segmentaciÃ³n volumÃ©trica
- [ ] ParticipaciÃ³n y benchmarking en el desafÃ­o BraTS
- [ ] Estudio de validaciÃ³n clÃ­nica con anotaciones de radiÃ³logos

---

## Referencias

### ArtÃ­culos Clave

1. **Tan, M., & Le, Q. (2021).** "EfficientNetV2: Smaller Models and Faster Training." *ICML 2021*.
2. **NyÃºl, L. G., & Udupa, J. K. (2000).** "On Standardizing the MR Image Intensity Scale." *Magnetic Resonance in Medicine*, 42(6), 1072-1081.
3. **Smith, S. M. (2002).** "Fast Robust Automated Brain Extraction." *Human Brain Mapping*, 17(3), 143-155.
4. **Tustison, N. J., et al. (2010).** "N4ITK: Improved N3 Bias Correction." *IEEE Transactions on Medical Imaging*, 29(6), 1310-1320.
5. **Guo, C., et al. (2017).** "On Calibration of Modern Neural Networks." *ICML 2017*.
6. **Selvaraju, R. R., et al. (2017).** "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization." *ICCV 2017*.
7. **Zhang, H., et al. (2018).** "mixup: Beyond Empirical Risk Minimization." *ICLR 2018*.

### Datasets

- **MasoudNickparvar:** [Brain Tumor MRI Dataset](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset) (Kaggle, 7K+ imÃ¡genes)
- **Navoneel:** [Brain MRI Images for Tumor Detection](https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection) (ValidaciÃ³n externa)
- **BraTS Challenge:** [Multimodal Brain Tumor Segmentation](https://www.med.upenn.edu/cbica/brats2024/) (IntegraciÃ³n futura)

---

## Licencia

Este proyecto se publica con fines acadÃ©micos y de investigaciÃ³n bajo la Licencia MIT.

**Importante:** Las adaptaciones para despliegue clÃ­nico requieren cumplimiento normativo (FDA, marcado CE) y validaciÃ³n mÃ©dica. Este software se proporciona "tal cual" Ãºnicamente con fines de investigaciÃ³n y no estÃ¡ destinado para uso diagnÃ³stico sin la validaciÃ³n clÃ­nica adecuada.

---

## CitaciÃ³n

Si utilizas este framework en tu investigaciÃ³n, por favor cÃ­talo:

```bibtex
@software{mercader2025brain,
  author = {Mercader MartÃ­nez, Francisco Javier},
  title = {Brain Tumor MRI Classification Framework: Medical-Grade Preprocessing and Cross-Dataset Validation},
  year = {2025},
  url = {https://github.com/franjavi-upct-es/Brain_Tumor_MRI},
  note = {Research framework with W\&B experiment tracking}
}
```

---

## Autor

**Francisco Javier Mercader MartÃ­nez**

- ğŸ“§ Email: [fcojavier.mercader04@gmail.com](fcojavier.mercader04@gmail.com)
- ğŸ’¼ LinkedIn: [Francisco Javier Mercader MartÃ­nez](www.linkedin.com/in/francisco-javier-mercader-martÃ­nez-b22768208)
- ğŸ“Š Experimentos W&B: [Ver en Vivo](https://wandb.ai/franciscojavier-mercader-upct-universidad-polit-cnica-de/brain-tumor-mri-portfolio)
<!-- - ğŸŒ Portfolio: [tu-sitio-web.com](https://tu-sitio-web.com) -->

---

<div align="center">

**â­ Si este proyecto te ayudÃ³, Â¡por favor dale una estrella al repositorio!**

[![GitHub stars](https://img.shields.io/github/stars/franjavi-upct-es/Brain_Tumor_MRI?style=social)](https://github.com/franjavi-upct-es/Brain_Tumor_MRI)

Hecho con ğŸ§  y â¤ï¸ para avanzar la investigaciÃ³n en IA mÃ©dica

</div>
